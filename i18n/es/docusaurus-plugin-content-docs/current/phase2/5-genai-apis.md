# Tema 5: APIs de IA generativa

> ‚è±Ô∏è **Tiempo estimado:** 4-5 d√≠as

La IA generativa y los Large Language Models (LLMs) est√°n cambiando c√≥mo construimos aplicaciones. En este tema vas a aprender a integrar APIs de LLMs en tus aplicaciones en Python. Estas habilidades son clave para cloud engineering moderno porque los servicios de IA se est√°n volviendo componentes centrales de las plataformas cloud.

---

## üìö Ruta de aprendizaje

### Entender lo b√°sico de una API de LLM

Antes de programar, entiende estos conceptos:

1. **Formato de mensajes**: los LLMs trabajan con entradas estilo conversaci√≥n
   - Mensaje system: define comportamiento/personalidad
   - Mensaje user: tu prompt/pregunta
   - Mensaje assistant: la respuesta de la IA

2. **Completions**: la API genera texto basado en tu input

3. **Par√°metros**:
   - `temperature`: controla aleatoriedad (0 = determinista, 1 = creativo)
   - `max_tokens`: limita la longitud de la respuesta
   - `model`: qu√© versi√≥n/modelo usar

4. **Structured outputs**: obtener JSON en vez de texto libre

## Aprendizaje pr√°ctico: Python OpenAI Demos

Antes de configurar recursos cloud, empieza con pr√°ctica gratis usando GitHub Models:

**Recurso:** [Python OpenAI Demos](https://aka.ms/python-openai-demos) ([Video Walkthrough](https://www.youtube.com/watch?v=_daw48A-RZI))

Este repo ense√±a el SDK de OpenAI para Python con ejemplos de dificultad progresiva‚Äîel mismo SDK que se usa con Azure OpenAI. Puedes correrlo **completamente gratis** usando GitHub Models en GitHub Codespaces.

**Acci√≥n:** haz estos ejemplos en orden:

1. **Chat Completions** - empieza con `chat.py`, luego prueba `chat_stream.py` y `chat_history.py`
2. **Structured Outputs** - aprende a obtener JSON con `structured_outputs_basic.py`
3. **Function Calling** - mira c√≥mo el LLM puede llamar tu c√≥digo con `function_calling_basic.py`

**¬øPor qu√© empezar aqu√≠?**
- ‚úÖ Gratis (usa GitHub Models, no necesitas tarjeta)
- ‚úÖ Funciona en el navegador (GitHub Codespaces)
- ‚úÖ Mismo SDK que vas a usar con Azure OpenAI
- ‚úÖ Construye habilidades paso a paso

### Serie de videos: Python + IA

Para aprender m√°s, revisa estos videos de la serie **Python + AI livestream** ([All Resources](https://aka.ms/pythonai/resources)):

| Tema | Slides | Video |
|------|--------|-------|
| LLMs | [Slides](https://aka.ms/pythonai/slides/llms) | [Watch](https://aka.ms/PythonAI107-f) |
| Structured Outputs | [Slides](https://aka.ms/pythonai/slides/structuredoutputs) | [Watch](https://aka.ms/PythonAI1015-f) |

> **Opcional:** la serie completa cubre 9 temas incluyendo RAG, AI Agents y m√°s. M√≠ralos todos si quieres un entendimiento profundo de Python + IA.

## Elige tu proveedor cloud

Cuando completes los demos, aplica tus habilidades al servicio de IA de tu proveedor. Esto te ense√±a skills cloud espec√≠ficos como IAM, administraci√≥n de recursos y billing.

- **Azure OpenAI** - si te enfocas en Azure (se accede v√≠a Azure AI Foundry)
- **AWS Bedrock** - si te enfocas en AWS (soporta Claude, Llama y otros)
- **GCP Vertex AI** - si te enfocas en Google Cloud (soporta Gemini y otros)

**Acci√≥n:** elige el proveedor que vaya con tu enfoque.

## Pr√°ctica en el playground del proveedor

**IMPORTANTE:** prueba en el playground ANTES de escribir c√≥digo.

### Azure OpenAI
- Estudia: [Azure OpenAI Chat Completions Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/chatgpt-quickstart)
- Acci√≥n: [Crea un recurso de Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/create-resource)
- Acci√≥n: [Usa el playground de chat de Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/chatgpt-quickstart?pivots=programming-language-studio)

### AWS Bedrock
- Estudia: [AWS Bedrock Getting Started](https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html)
- Acci√≥n: [Usa el playground de AWS Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/playgrounds.html)
- Acci√≥n: habilita acceso a modelos (Claude o Llama) en tu regi√≥n

### GCP Vertex AI
- Estudia: [Vertex AI Generative AI Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview)
- Acci√≥n: [Usa Vertex AI Studio](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-text)
- Acci√≥n: prueba prompts en la interfaz de texto

## Ejercicios en el playground

En el playground del proveedor que elegiste, prueba estos prompts:

1. **Completado simple**:
   ```
   Analyze the sentiment of this text: "I learned so much about Python today!"
   ```

2. **Salida estructurada**:
   ```
   Analyze the sentiment of this journal entry and respond in JSON format with fields: sentiment (positive/negative/neutral) and summary (2 sentences max).
   
   Journal entry: "Today I struggled with async Python but finally got it working after 3 hours."
   ```

3. **Prueba con system message**: agrega un system message:
   ```
   System: You are a helpful learning coach who analyzes student journal entries.
   User: Analyze this entry: "I'm frustrated with databases but making progress."
   ```

Toma screenshots de respuestas exitosas. Luego vas a replicar esto en c√≥digo.

## Integraci√≥n con SDK de Python

Ahora implementa los mismos prompts en Python.

### Azure OpenAI SDK
- Acci√≥n: [Azure OpenAI Python Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/chatgpt-quickstart?pivots=programming-language-python)
- Instala: `pip install openai`

### AWS Bedrock SDK
- Acci√≥n: [AWS Bedrock Python SDK Examples](https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started-api.html)
- Instala: `pip install boto3`

### GCP Vertex AI SDK
- Acci√≥n: [Vertex AI Python SDK Quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
- Instala: `pip install google-cloud-aiplatform`

## Conceptos clave que debes dominar

Recorre la documentaci√≥n de Python del proveedor que elegiste y aseg√∫rate de entender:

1. **Autenticaci√≥n**: API keys, service principals o IAM roles
2. **Hacer requests**: enviar mensajes al LLM
3. **Manejar respuestas**: parsear el texto de salida
4. **Manejo de errores**: rate limits, timeouts, requests inv√°lidos
5. **Variables de entorno**: guardar keys de forma segura (¬°NUNCA subas keys a git!)
6. **Soporte async**: usar async/await con APIs de LLM

## Ejercicio de pr√°ctica

Crea un script `llm_test.py` que:

1. Cargue credenciales desde variables de entorno
2. Env√≠e el texto de una entrada de journal al LLM
3. Pida an√°lisis de sentimiento (positivo/negativo/neutral)
4. Pida un resumen de 2 oraciones
5. Imprima los resultados de forma clara

Ejemplo de entrada para probar:
```
"Today I learned about FastAPI and built my first endpoint. The automatic documentation is amazing! I struggled a bit with async functions but the official tutorial helped. Tomorrow I'll tackle database integration."
```

## Conciencia de costos

Las APIs de LLM se cobran por uso. Costos t√≠picos para esta fase:
- ~$0.50 - $3.00 para pruebas y completar el capstone
- Se cobran tokens tanto de entrada (prompt) como de salida (respuesta)
- Prompts m√°s largos = m√°s costo
- Modelos m√°s grandes (GPT-4o, Claude Sonnet) = m√°s costosos que modelos peque√±os (GPT-4o-mini, Claude Haiku)

**Tip:** usa modelos m√°s peque√±os y r√°pidos para desarrollo y pruebas. Cambia a modelos grandes solo cuando lo necesites.

---

## üß™ Pon a prueba tu conocimiento

Cuando termines los tutoriales, usa un asistente de IA para evaluar tu entendimiento. Ejemplos de prompts:

1. ¬øPuedes explicar qu√© es una API de un LLM y c√≥mo se diferencia de una REST API tradicional?
2. ¬øPuedes explicar el rol de system messages, user messages y assistant messages?
3. ¬øPuedes evaluarme sobre qu√© controla el par√°metro temperature?
4. ¬øPuedes explicar c√≥mo guardar API keys de forma segura en una app de Python?
5. ¬øPuedes pedirme que explique la diferencia entre llamadas s√≠ncronas y as√≠ncronas a una API de LLM?
6. ¬øPuedes evaluarme sobre c√≥mo manejar errores y rate limits al llamar APIs de LLM?
7. ¬øPuedes explicar c√≥mo obtener salida estructurada JSON en vez de texto libre?

---

## ‚úÖ Checklist del tema

Antes de seguir, aseg√∫rate de tener:

- [ ] Completado los ejercicios de Python OpenAI Demos
- [ ] Probado prompts en el playground del proveedor (Azure AI Foundry, AWS Bedrock o Vertex AI)
- [ ] Entendido el formato de mensajes (system, user, assistant)
- [ ] Practicado salidas estructuradas (respuestas JSON)
- [ ] Creado un script en Python que llama una API de LLM
- [ ] Guardado API keys de forma segura en variables de entorno
- [ ] Entendido lo b√°sico de costos y tokens

---

